{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499f4352-f904-4a56-a60a-da87639f534c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T00:43:58.175749Z",
     "iopub.status.busy": "2023-06-24T00:43:58.175403Z",
     "iopub.status.idle": "2023-06-24T00:43:58.180395Z",
     "shell.execute_reply": "2023-06-24T00:43:58.179728Z",
     "shell.execute_reply.started": "2023-06-24T00:43:58.175712Z"
    },
    "tags": []
   },
   "source": [
    "# Task 6.5 Unsupervised Machine Learning: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9550e-3c4b-4534-91ee-d03f60553590",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Standard prerequisites.  Now with additional modules 'KMeans' and 'pylab' - from the libraries 'scikit-learn' and 'matplotlib', respectively - as of Exercise/Task 6.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5049a44b-1cc2-4c93-b3a3-3bf8d4862fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:15.986031Z",
     "start_time": "2023-06-12T20:08:13.649526Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:42.873342Z",
     "iopub.status.busy": "2023-06-30T01:55:42.873028Z",
     "iopub.status.idle": "2023-06-30T01:55:44.518824Z",
     "shell.execute_reply": "2023-06-30T01:55:44.518273Z",
     "shell.execute_reply.started": "2023-06-30T01:55:42.873269Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "# I'm trying modin as a drop-in replace-- er, enhancement to pandas; supposedly it will help use more than one CPU core.\n",
    "# Nope.  I'm having too much trouble getting modin installed, so it's back to plain old Pandas for now. :-(\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8eb3cd9-a923-44ed-94b5-7009da7a9ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:44.520474Z",
     "iopub.status.busy": "2023-06-30T01:55:44.519889Z",
     "iopub.status.idle": "2023-06-30T01:55:44.596695Z",
     "shell.execute_reply": "2023-06-30T01:55:44.595826Z",
     "shell.execute_reply.started": "2023-06-30T01:55:44.520447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import scikit-learn library and select modules for Task 6.4 (see more imports for Task 6.5, next).\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3293f2-0185-47ca-81c0-1a14c0abd096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:44.598006Z",
     "iopub.status.busy": "2023-06-30T01:55:44.597718Z",
     "iopub.status.idle": "2023-06-30T01:55:44.728224Z",
     "shell.execute_reply": "2023-06-30T01:55:44.727520Z",
     "shell.execute_reply.started": "2023-06-30T01:55:44.597973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import additional modules 'KMeans' and 'pylab' - from the libraries 'scikit-learn' and 'matplotlib', respectively - for Task 6.5\n",
    "from sklearn.cluster import KMeans # Here is where you import the k-means algorithm from scikit-learn.\n",
    "import pylab as pl # PyLab is a convenience module that bulk imports matplotlib.\n",
    "# (Note to self:  learn more about Python imports, particularly why we don't say, \"import matplotlib.pylab as pl\" or \"from matplotlib import pylab ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f4beba-6082-4a6f-8c0d-d1dbfbf7fdaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:44.730081Z",
     "iopub.status.busy": "2023-06-30T01:55:44.729885Z",
     "iopub.status.idle": "2023-06-30T01:55:45.031834Z",
     "shell.execute_reply": "2023-06-30T01:55:45.031299Z",
     "shell.execute_reply.started": "2023-06-30T01:55:44.730059Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import folium and JSON libraries for Task 6.3.\n",
    "import folium\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f524e51-4fb4-4a61-b10e-58e4748d2f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.033254Z",
     "iopub.status.busy": "2023-06-30T01:55:45.032712Z",
     "iopub.status.idle": "2023-06-30T01:55:45.035739Z",
     "shell.execute_reply": "2023-06-30T01:55:45.035218Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.033227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For future reference, Exercise 6.2 introduced graphical libraries Bokeh and Plotly.\n",
    "# import bokeh\n",
    "# import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a28d63-c246-4673-bb63-33d3c8560084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:15.992831Z",
     "start_time": "2023-06-12T20:08:15.988513Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.037103Z",
     "iopub.status.busy": "2023-06-30T01:55:45.036824Z",
     "iopub.status.idle": "2023-06-30T01:55:45.042785Z",
     "shell.execute_reply": "2023-06-30T01:55:45.041718Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.037076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Starting with Exercise 4.7, import additional libraries I've discovered thanks to Lubov, especially the time library.\n",
    "import time\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a454069-26de-4879-85a6-19b21f1dbe6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:15.999865Z",
     "start_time": "2023-06-12T20:08:15.996013Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.044702Z",
     "iopub.status.busy": "2023-06-30T01:55:45.044396Z",
     "iopub.status.idle": "2023-06-30T01:55:45.049585Z",
     "shell.execute_reply": "2023-06-30T01:55:45.048418Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.044668Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import itertools to help loop through lots of things.\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76beb3c2-941b-4284-94dc-8cca331bf396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.005997Z",
     "start_time": "2023-06-12T20:08:16.002994Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.052093Z",
     "iopub.status.busy": "2023-06-30T01:55:45.051550Z",
     "iopub.status.idle": "2023-06-30T01:55:45.057547Z",
     "shell.execute_reply": "2023-06-30T01:55:45.056121Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.052041Z"
    }
   },
   "outputs": [],
   "source": [
    "# I want to convert Date-Timestamps into UNIX Epoch time for analysis.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1162997c-d162-4219-8cf4-93e0beeae591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.011947Z",
     "start_time": "2023-06-12T20:08:16.008775Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.059534Z",
     "iopub.status.busy": "2023-06-30T01:55:45.059221Z",
     "iopub.status.idle": "2023-06-30T01:55:45.065117Z",
     "shell.execute_reply": "2023-06-30T01:55:45.064159Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.059503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set a PATH variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81bc4e33-c5ea-4f16-9c83-924ed525ff45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.017084Z",
     "start_time": "2023-06-12T20:08:16.014098Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.068400Z",
     "iopub.status.busy": "2023-06-30T01:55:45.067583Z",
     "iopub.status.idle": "2023-06-30T01:55:45.072595Z",
     "shell.execute_reply": "2023-06-30T01:55:45.071516Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.068373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Linux PATH, local - Sadly, my Linux system with 8GB of total RAM could not import the full dataset.\n",
    "# I have moved to an AWS EC2 instance that should be able to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fb5250-ac77-48b1-b76d-b86618648c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.022791Z",
     "start_time": "2023-06-12T20:08:16.019569Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.075719Z",
     "iopub.status.busy": "2023-06-30T01:55:45.075067Z",
     "iopub.status.idle": "2023-06-30T01:55:45.079021Z",
     "shell.execute_reply": "2023-06-30T01:55:45.078308Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.075691Z"
    }
   },
   "outputs": [],
   "source": [
    "## path = (r'~/careerfoundry/tasks/data-immersion/Achievement6/Project/02-Data/Original-Data/US-Weather-Events.2016-2021/www.kaggle.com/datasets/sobhanmoosavi/us-weather-events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce766e-5e7f-47c3-93bf-7d6841adcc09",
   "metadata": {},
   "source": [
    "### # Oh, wow, matplotlib.pyplot.savefig function does not expand the tilde (~) reference in directory paths.  LAME. :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "156f4c12-2a79-449f-94e0-59e772251152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.028756Z",
     "start_time": "2023-06-12T20:08:16.025218Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.080356Z",
     "iopub.status.busy": "2023-06-30T01:55:45.080100Z",
     "iopub.status.idle": "2023-06-30T01:55:45.086139Z",
     "shell.execute_reply": "2023-06-30T01:55:45.085427Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.080328Z"
    }
   },
   "outputs": [],
   "source": [
    "path = (r'/home/ubuntu/careerfoundry/tasks/data-immersion/Achievement6/Project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bdc066-3e85-428d-b3e6-f7ef1d861e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.036588Z",
     "start_time": "2023-06-12T20:08:16.032541Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.087351Z",
     "iopub.status.busy": "2023-06-30T01:55:45.087150Z",
     "iopub.status.idle": "2023-06-30T01:55:45.091273Z",
     "shell.execute_reply": "2023-06-30T01:55:45.090736Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.087328Z"
    }
   },
   "outputs": [],
   "source": [
    "# windoze PATH - The windoze laptop I bought for Excel and Tableau also has 16GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e227af7a-25c0-443e-98e9-ac8c01cb69e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T20:08:16.045467Z",
     "start_time": "2023-06-12T20:08:16.042321Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.092494Z",
     "iopub.status.busy": "2023-06-30T01:55:45.092203Z",
     "iopub.status.idle": "2023-06-30T01:55:45.096432Z",
     "shell.execute_reply": "2023-06-30T01:55:45.095696Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.092463Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## path = (r'C:\\Users\\emccc\\OneDrive\\Documents\\CareerFoundry\\Achievement-4\\Instacart-Basket-Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7863d668-441e-4b4f-b941-5679a0e14f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.097896Z",
     "iopub.status.busy": "2023-06-30T01:55:45.097617Z",
     "iopub.status.idle": "2023-06-30T01:55:45.103660Z",
     "shell.execute_reply": "2023-06-30T01:55:45.102857Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.097863Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This command propts matplotlib visuals to appear in the notebook \n",
    "# This option ensures that the graphs you create are displayed within the notebook without the need to \"call\" them specifically.\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d1ce1-25cb-4b12-b879-e143bf58f2fd",
   "metadata": {},
   "source": [
    "## Load and check our updated dataframe for Texas weather from Task 6.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102d88e-537d-45d9-83df-c2c68dfae2d1",
   "metadata": {},
   "source": [
    "### (There were no changes to our dataframe in Task 6.4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392f1abc-803b-47f1-ba32-bb207b92cdf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.105714Z",
     "iopub.status.busy": "2023-06-30T01:55:45.105166Z",
     "iopub.status.idle": "2023-06-30T01:55:45.494779Z",
     "shell.execute_reply": "2023-06-30T01:55:45.494041Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.105669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(path, '02-Data','Prepared-Data', 'df_texas.Task-6.3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4bbdd8-c923-4490-b97a-36b5b48627d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.495921Z",
     "iopub.status.busy": "2023-06-30T01:55:45.495725Z",
     "iopub.status.idle": "2023-06-30T01:55:45.503294Z",
     "shell.execute_reply": "2023-06-30T01:55:45.502634Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.495898Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515813, 34)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe5cbec6-f569-4b23-b5c1-feb6182eec72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.504673Z",
     "iopub.status.busy": "2023-06-30T01:55:45.504433Z",
     "iopub.status.idle": "2023-06-30T01:55:45.510856Z",
     "shell.execute_reply": "2023-06-30T01:55:45.510101Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.504649Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EventId', 'Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)',\n",
       "       'Precipitation(in)', 'TimeZone', 'AirportCode', 'LocationLat',\n",
       "       'LocationLng', 'County', 'State', 'StartTime(Epoch)', 'EndTime(Epoch)',\n",
       "       'Duration(seconds)', 'Duration(hours)',\n",
       "       'PrecipitationRate(inches/hour)', 'Disbelievable', 'Region',\n",
       "       'StartYear', 'StartYear-Month', 'Snow(in)', 'Rain(in)', 'StartMonth',\n",
       "       'Rain-sum-AC-SY-M', 'Rain-sum-AC-SY', 'Snow-sum-AC-SY-M',\n",
       "       'Snow-sum-AC-SY', 'CO-Num-AC', 'Rain-sumavg-CO-SY-M',\n",
       "       'Rain-sumavg-CO-SY', 'Snow-sumavg-CO-SY-M', 'Snow-sumavg-CO-SY',\n",
       "       'GeoJSONCounty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d10da-bd10-42c1-9498-1141b4ecece0",
   "metadata": {},
   "source": [
    "# Step 2:  Import your data and conduct any necessary cleaning, manipulations, and reprocessing (such as renaming).\n",
    "\n",
    "##    Recall from the Exercise that the k-means algorithm can only handle numerical variables, so you’ll need to remove any categorical columns from your data.\n",
    "##    Also recall that the difference between your variables’ scales can’t be too large or your results will be biased. Make sure you standardize your data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae2f131-6f72-43a8-ac17-ab5a53386b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.512839Z",
     "iopub.status.busy": "2023-06-30T01:55:45.512088Z",
     "iopub.status.idle": "2023-06-30T01:55:45.526521Z",
     "shell.execute_reply": "2023-06-30T01:55:45.525984Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.512810Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's create a new dataframe with just the essential numeric columns.\n",
    "df_k_means = df[['LocationLat', 'LocationLng', 'StartTime(Epoch)', 'EndTime(Epoch)', 'Rain-sumavg-CO-SY', 'Snow-sumavg-CO-SY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744a7761-63db-49f9-902b-565cf3fe9727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.527878Z",
     "iopub.status.busy": "2023-06-30T01:55:45.527351Z",
     "iopub.status.idle": "2023-06-30T01:55:45.533308Z",
     "shell.execute_reply": "2023-06-30T01:55:45.532231Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.527851Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515813, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89150c07-fdc9-4929-8af2-788e5090965c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.534522Z",
     "iopub.status.busy": "2023-06-30T01:55:45.534329Z",
     "iopub.status.idle": "2023-06-30T01:55:45.548094Z",
     "shell.execute_reply": "2023-06-30T01:55:45.547531Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.534500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationLat</th>\n",
       "      <th>LocationLng</th>\n",
       "      <th>StartTime(Epoch)</th>\n",
       "      <th>EndTime(Epoch)</th>\n",
       "      <th>Rain-sumavg-CO-SY</th>\n",
       "      <th>Snow-sumavg-CO-SY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136752</th>\n",
       "      <td>31.8111</td>\n",
       "      <td>-106.3758</td>\n",
       "      <td>1451997600</td>\n",
       "      <td>1452004800</td>\n",
       "      <td>10.565</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136753</th>\n",
       "      <td>31.8111</td>\n",
       "      <td>-106.3758</td>\n",
       "      <td>1452019500</td>\n",
       "      <td>1452023280</td>\n",
       "      <td>10.565</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136754</th>\n",
       "      <td>31.8111</td>\n",
       "      <td>-106.3758</td>\n",
       "      <td>1452085800</td>\n",
       "      <td>1452093900</td>\n",
       "      <td>10.565</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136755</th>\n",
       "      <td>31.8111</td>\n",
       "      <td>-106.3758</td>\n",
       "      <td>1452093900</td>\n",
       "      <td>1452095040</td>\n",
       "      <td>10.565</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136756</th>\n",
       "      <td>31.8111</td>\n",
       "      <td>-106.3758</td>\n",
       "      <td>1452095040</td>\n",
       "      <td>1452097200</td>\n",
       "      <td>10.565</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LocationLat  LocationLng  StartTime(Epoch)  EndTime(Epoch)  \\\n",
       "136752      31.8111    -106.3758        1451997600      1452004800   \n",
       "136753      31.8111    -106.3758        1452019500      1452023280   \n",
       "136754      31.8111    -106.3758        1452085800      1452093900   \n",
       "136755      31.8111    -106.3758        1452093900      1452095040   \n",
       "136756      31.8111    -106.3758        1452095040      1452097200   \n",
       "\n",
       "        Rain-sumavg-CO-SY  Snow-sumavg-CO-SY  \n",
       "136752             10.565              0.055  \n",
       "136753             10.565              0.055  \n",
       "136754             10.565              0.055  \n",
       "136755             10.565              0.055  \n",
       "136756             10.565              0.055  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k_means.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001547f-172c-4691-8339-25aebdc3db56",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The scales of these columns' values differ by several orders of magnitude.  \"Standardization\" is needed.\n",
    "## However, it's not clear to me that any PCA (Principal Components Analysis) is needed.  We shall see.\n",
    "#### For future reference, the following articles seem very helpful:\n",
    "#### https://www.geeksforgeeks.org/how-to-standardize-data-in-a-pandas-dataframe/\n",
    "#### http://varianceexplained.org/r/kmeans-free-lunch/\n",
    "#### https://365datascience.com/tutorials/python-tutorials/pca-k-means/\n",
    "#### https://365datascience.com/tutorials/statistics-tutorials/standardization/\n",
    "#### https://365datascience.com/tutorials/python-tutorials/principal-components-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77396b36-8764-4a16-8e41-7143c63d73c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.549616Z",
     "iopub.status.busy": "2023-06-30T01:55:45.549057Z",
     "iopub.status.idle": "2023-06-30T01:55:45.936484Z",
     "shell.execute_reply": "2023-06-30T01:55:45.935687Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.549591Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14422/341357248.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()\n",
      "/tmp/ipykernel_14422/341357248.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()\n",
      "/tmp/ipykernel_14422/341357248.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()\n",
      "/tmp/ipykernel_14422/341357248.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()\n",
      "/tmp/ipykernel_14422/341357248.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()\n",
      "/tmp/ipykernel_14422/341357248.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()\n"
     ]
    }
   ],
   "source": [
    "# Z-Score using pandas\n",
    "for col in df_k_means.columns.tolist():\n",
    "    df_k_means[[col]] = (df_k_means[[col]] - df_k_means[[col]].mean()) / df_k_means[[col]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8eec5e6-600e-405c-8c8c-58b5f74706d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.939206Z",
     "iopub.status.busy": "2023-06-30T01:55:45.938878Z",
     "iopub.status.idle": "2023-06-30T01:55:45.945250Z",
     "shell.execute_reply": "2023-06-30T01:55:45.943956Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.939179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515813, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e525322f-b7b6-4251-aeae-077d8d98201c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.947411Z",
     "iopub.status.busy": "2023-06-30T01:55:45.946596Z",
     "iopub.status.idle": "2023-06-30T01:55:45.959978Z",
     "shell.execute_reply": "2023-06-30T01:55:45.959010Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.947375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationLat</th>\n",
       "      <th>LocationLng</th>\n",
       "      <th>StartTime(Epoch)</th>\n",
       "      <th>EndTime(Epoch)</th>\n",
       "      <th>Rain-sumavg-CO-SY</th>\n",
       "      <th>Snow-sumavg-CO-SY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136752</th>\n",
       "      <td>0.417658</td>\n",
       "      <td>-3.921755</td>\n",
       "      <td>-1.704822</td>\n",
       "      <td>-1.704761</td>\n",
       "      <td>-1.078743</td>\n",
       "      <td>-0.30681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136753</th>\n",
       "      <td>0.417658</td>\n",
       "      <td>-3.921755</td>\n",
       "      <td>-1.704415</td>\n",
       "      <td>-1.704418</td>\n",
       "      <td>-1.078743</td>\n",
       "      <td>-0.30681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136754</th>\n",
       "      <td>0.417658</td>\n",
       "      <td>-3.921755</td>\n",
       "      <td>-1.703184</td>\n",
       "      <td>-1.703106</td>\n",
       "      <td>-1.078743</td>\n",
       "      <td>-0.30681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136755</th>\n",
       "      <td>0.417658</td>\n",
       "      <td>-3.921755</td>\n",
       "      <td>-1.703033</td>\n",
       "      <td>-1.703085</td>\n",
       "      <td>-1.078743</td>\n",
       "      <td>-0.30681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136756</th>\n",
       "      <td>0.417658</td>\n",
       "      <td>-3.921755</td>\n",
       "      <td>-1.703012</td>\n",
       "      <td>-1.703045</td>\n",
       "      <td>-1.078743</td>\n",
       "      <td>-0.30681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LocationLat  LocationLng  StartTime(Epoch)  EndTime(Epoch)  \\\n",
       "136752     0.417658    -3.921755         -1.704822       -1.704761   \n",
       "136753     0.417658    -3.921755         -1.704415       -1.704418   \n",
       "136754     0.417658    -3.921755         -1.703184       -1.703106   \n",
       "136755     0.417658    -3.921755         -1.703033       -1.703085   \n",
       "136756     0.417658    -3.921755         -1.703012       -1.703045   \n",
       "\n",
       "        Rain-sumavg-CO-SY  Snow-sumavg-CO-SY  \n",
       "136752          -1.078743           -0.30681  \n",
       "136753          -1.078743           -0.30681  \n",
       "136754          -1.078743           -0.30681  \n",
       "136755          -1.078743           -0.30681  \n",
       "136756          -1.078743           -0.30681  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k_means.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6337778-1f56-40f1-87aa-f495a0b34562",
   "metadata": {},
   "source": [
    "# Step 3:  Use the elbow technique as shown in the Jupyter notebook for this Exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34de08-73c8-471f-a2b5-a272b03e7832",
   "metadata": {},
   "source": [
    "## The Elbow Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df8a30bb-b6b2-4dab-84f7-a13f19db516f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.961692Z",
     "iopub.status.busy": "2023-06-30T01:55:45.961388Z",
     "iopub.status.idle": "2023-06-30T01:55:45.966006Z",
     "shell.execute_reply": "2023-06-30T01:55:45.965186Z",
     "shell.execute_reply.started": "2023-06-30T01:55:45.961666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cl = range(1, 10) # Defines the range of potential clusters in the data.\n",
    "kmeans = [KMeans(n_clusters=i) for i in num_cl] # Defines k-means clusters in the range assigned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab41609-f626-4144-91a1-16e579615f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T01:55:45.967268Z",
     "iopub.status.busy": "2023-06-30T01:55:45.967065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = [kmeans[i].fit(df_k_means).score(df_k_means) for i in range(len(kmeans))] # Creates a score that represents \n",
    "# a rate of variation for the given cluster option.\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f9797-185d-4a8a-bbe9-e81b5b65dadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the elbow curve using PyLab.\n",
    "\n",
    "pl.plot(num_cl,score)\n",
    "pl.xlabel('Number of Clusters')\n",
    "pl.ylabel('Score')\n",
    "pl.title('Elbow Curve')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03926259-c31c-4226-811c-d657d7c97c4f",
   "metadata": {},
   "source": [
    "# Step 4:  Make an informed decision about the number of clusters you’ll use in your k-means algorithm based on the chart.\n",
    "## Explain why you chose that number in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233693c-74bd-4622-a1b8-8133e6fb5e62",
   "metadata": {},
   "source": [
    "### Answer:  it looks like the graph smooths out mostly at 2, but there is also a slight additional smoothing at 3.\n",
    "### I will try 3, first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d3510-2d9a-489d-b752-19c92208a759",
   "metadata": {},
   "source": [
    "# Step 5:  Run the k-means algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442dbc00-b90d-4953-b157-0a3c391d032a",
   "metadata": {},
   "source": [
    "## First, we will try for three clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1318009-8d37-4627-9ccc-22a59c994075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the k-means object.\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76363e-7553-4a14-b335-e917c87a988d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the k-means object to the data.\n",
    "\n",
    "kmeans.fit(df_k_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4beae11-47b7-448f-86ea-e79b312c1c8d",
   "metadata": {},
   "source": [
    "# Step 6:  Attach a new column to your dataframe with the resulting clusters as shown in the Exercise. This will allow you to create a visualization using your clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ee85f-623a-47b1-a59b-95301f9b110b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_k_means['clusters-3'] = kmeans.fit_predict(df_k_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802b068-32fd-441a-9c3f-f5197ed9e01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_k_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b08e4f-244d-4585-b71b-5dfe4927dd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_k_means['clusters-3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aafd587-512b-4a51-9f02-f6e08e33612a",
   "metadata": {},
   "source": [
    "## This looks like two clusters of nearly identical size, plus a third cluster that is only about one-third that size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc030c16-9906-47b4-9fc7-cae6ada99110",
   "metadata": {},
   "source": [
    "# Step 7:  Create a few different visualizations (e.g., scatterplots) using your clustered data. Try plotting different variables against each other to see the results in terms of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0e6d2-27f9-4c76-a901-43abdad0d6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the clusters for LONGITUDE and yearly RAINFALL average.\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.scatterplot(x=df_k_means['LocationLng'], y=df_k_means['Rain-sumavg-CO-SY'], hue=kmeans.labels_, s=100) \n",
    "# Here, you're subsetting `X` for the x and y arguments to avoid using their labels. \n",
    "# `hue` takes the value of the attribute `kmeans.labels_`, which is the result of running the k-means algorithm.\n",
    "# `s` represents the size of the points you want to see in the plot.\n",
    "\n",
    "ax.grid(False) # This removes the grid from the background.\n",
    "plt.xlabel('Location Longitude') # Label x-axis.\n",
    "plt.ylabel('Total Yearly County Rainfall Average') # Label y-axis.\n",
    "plt.savefig(os.path.join(path, '04-Analysis', 'Visualizations', 'task-6.5-kmeans-cluster-scatter-longitude-vs-rainfall.png'), facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac3815-0d43-4bf5-b511-2cbddb7fc6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the clusters for TIME and yearly RAINFALL average.\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.scatterplot(x=df_k_means['StartTime(Epoch)'], y=df_k_means['Rain-sumavg-CO-SY'], hue=kmeans.labels_, s=100) \n",
    "# Here, you're subsetting `X` for the x and y arguments to avoid using their labels. \n",
    "# `hue` takes the value of the attribute `kmeans.labels_`, which is the result of running the k-means algorithm.\n",
    "# `s` represents the size of the points you want to see in the plot.\n",
    "\n",
    "ax.grid(False) # This removes the grid from the background.\n",
    "plt.xlabel('Start Time') # Label x-axis.\n",
    "plt.ylabel('Total Yearly County Rainfall Average') # Label y-axis.\n",
    "plt.savefig(os.path.join(path, '04-Analysis', 'Visualizations', 'task-6.5-kmeans-cluster-scatter-time-vs-rainfall.png'), facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b5537-17f3-40c3-a6a4-a32d78982c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the clusters for LATITUDE and yearly SNOWFALL average (Snow-sumavg-CO-SY),\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.scatterplot(x=df_k_means['LocationLat'], y=df_k_means['Snow-sumavg-CO-SY'], hue=kmeans.labels_, s=100) \n",
    "# Here, you're subsetting `X` for the x and y arguments to avoid using their labels. \n",
    "# `hue` takes the value of the attribute `kmeans.labels_`, which is the result of running the k-means algorithm.\n",
    "# `s` represents the size of the points you want to see in the plot.\n",
    "\n",
    "ax.grid(False) # This removes the grid from the background.\n",
    "plt.xlabel('Location Latitude') # Label x-axis.\n",
    "plt.ylabel('Total Yearly County Snowfall Average') # Label y-axis.\n",
    "plt.savefig(os.path.join(path, '04-Analysis', 'Visualizations', 'task-6.5-kmeans-cluster-scatter-latitude-vs-snowfall.png'), facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ae3f5-76ac-4e95-89e8-7da36396ca14",
   "metadata": {},
   "source": [
    "# Step 8:  Discuss how and why the clusters make (or do not make) sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a53a6b-b393-4e70-af9a-714e02d87b85",
   "metadata": {},
   "source": [
    "## The first plot, for the clusters of LONGITUDE and yearly RAINFALL average, seems to make sense.  Towards the lower end of the longitude range (i.e. to the west), we have both the lowest rainfall averages and the fewest readings (i.e. the airport locations - where the weather events are reported - are more sparse).  Interestingly, the two larger clusters to the east appear to show a difference in the rainfall averages:  perhaps we need to combine another factor (such as frequency of particular events besides rain) to explain this.\n",
    "## The second plot, for the clusters of TIME (from the StartTime(Epoch) column) and yearly RAINFALL average, is tricky.  It shows the smallest cluster (corresponding to locations to the west from the previous plot) interspersed among the larger two clusters, which might indicate we do not have very good clustering for it.  However, the two larger clusters show a greater distinction from each other, with one cluster appearing almost exclusively to the left (i.e. earlier in time) - as well as a broader range of rainfall averages - and the other cluster appearing almost exclusively to the right (i.e. later) - and with much lower rainfall avarages.  I'm not sure what might explain this:  it gives me the impression that the readings from some airports were phased out over time, with readings from other (drier) airports taking their place, but this does not seem very plausible en masse.  In my background reading, I learned that new generations of meterological equipment do get phased in over time, but I'm not sure that is a plausible explanation over such a short timescale (less than three and a half years).  *Could it be an artifact of the standardization process??*\n",
    "## The third plot, for the clusters of LATITUDE and yearly SNOWFALL average, shows essentially total overlap (i.e. no difference) between the two larger clusters, which makes sense, because very little snow is expected at their lower latitudes.  The smaller cluster (which is both more westerly and more northerly) shows at least partial differentiation with some of its northern-most datapoints corresponding to higher snowfall totals, but it's not a very clean separation from the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac284490-770d-4441-b817-e9a3207b747c",
   "metadata": {},
   "source": [
    "# Step 9:  Calculate the descriptive statistics for your clusters using the groupby() function and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78f49c-7231-4b32-a327-47d11f972f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_k_means.loc[df_k_means['clusters-3'] == 2, 'cluster'] = 'dark purple'\n",
    "df_k_means.loc[df_k_means['clusters-3'] == 1, 'cluster'] = 'purple'\n",
    "df_k_means.loc[df_k_means['clusters-3'] == 0, 'cluster'] = 'pink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5b848-6c6b-43b8-862f-574dbba5785a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_k_means.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b47a7-e27c-4fb0-bc21-03a37898fdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_k_means.groupby('cluster').agg({'LocationLat':['mean', 'median'], \n",
    "                         'LocationLng':['mean', 'median'], \n",
    "                         'StartTime(Epoch)':['mean', 'median'], \n",
    "                         'Rain-sumavg-CO-SY':['mean', 'median'],\n",
    "                          'Snow-sumavg-CO-SY':['mean', 'median']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e3461-a9ec-42b2-82e2-ca4a405227bf",
   "metadata": {},
   "source": [
    "## Discussion of findings:\n",
    "## The Purple and Dark Purple are the two larger groups of comparable size, while the Pink group is the much smaller group.\n",
    "## The Purple group is somewhat more northerly and easterly than the Dark Purple group, while the Pink group is more to the north and west than either of them.\n",
    "## There seem to be significant differences in the times for the groups' measurements, with Purple being much earlier than Pink, and Dark Purple being much later, but I suspect this to be an artifact of the standardization process.\n",
    "## As mentioned in the discussion of the first plot, the Pink group has the lowest rainfall, but there is also a difference between the other two groupsm, with Purple having significantly higher amounts than Dark Purple.\n",
    "## For snowfall, the Purple and Dark Purple groups are nearly identical in their medians, but the Dark Purple group actually appears closer to the Pink group for its mean.  The Pink group has both a higher mean and median than either of the others - as noted earlier, it has some clear separation with higher latitude and snowfall numbers - but the separation from the Dark Purple group is not complete; the earlier plot shows some mixing between the groups, and the closer proximity of mean values between the Pink and Dark Purple groups would seem to reflect this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8f6d1-2d12-446d-88ca-5e0693efcb32",
   "metadata": {},
   "source": [
    "# Step 10:  Propose what these results could be useful for in future steps of an analytics pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576b9c0-0864-4a58-94e1-f616bcbabc4d",
   "metadata": {},
   "source": [
    "## The clustering results are not as simple as one might like.\n",
    "## 1) On the one hand, the clusters have some intermingling, which is an indication that the variables being examined do not have strong correlations (and that is not surprising, given previous results in this Achievement).\n",
    "## 2) On the other hand, for the two larger clusters sharing strong overlap in latitude and longitude, to have such striking differences in StartTime and yearly Rainfall averages, raises concerns as to how the data was collected or whether we're not analyzing it correctly.\n",
    "## I'm hopeful that the next Exercise on time series will provide additional tools and methds to dig deeper into our Time columns, and find stronger correlations for point 1), or at least solve the mystery of point 2).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
